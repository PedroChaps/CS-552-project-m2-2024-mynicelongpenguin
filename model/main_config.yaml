"team_name": "MyNiceLongPenguin" # Your team name
"eval_method": ["reward"] # mcqa, reward, rag, compression
"task_type": "causal_lm" # causal_lm, seq2seq
"policy_model_path": "/scratch/izar/hogenhau/project-m2-2024-mynicelongpenguin/model/models/outputs/final_model_40k_label_smoothing_0DOT25" # Your path to the final checkpoint
"reference_model_path": "rhysjones/phi-2-orange-v2" # The repo id of your pretrained reference model
"quantized_policy_model_path": "./checkpoints/best_model_quantized/" # Your path to the final quantized checkpoint
"rag_policy_model_path": "./checkpoints/best_model_rag/" # Your path to the final RAG checkpoint
# "test_data_path": "./datasets/dpo_preference_example.jsonl" # Your path to the test data
# "test_data_path": "/scratch/izar/hogenhau/project-m2-2024-mynicelongpenguin/data/combined_test.jsonl" # Your path to the test data
"test_data_path": "/scratch/izar/hogenhau/project-m2-2024-mynicelongpenguin/data/combined_test.jsonl" # Your path to the test data
# "test_data_path": "/scratch/izar/hogenhau/project-m2-2024-mynicelongpenguin/model/datasets/dpo_preference_example.jsonl" # Your path to the test data
# "dpo_model_args": null # Put any model arguments required to load your DPO model below
"dpo_model_args": # Put any model arguments required to load your DPO model below
  "trust_remote_code": True
  # "torch_dtype": torch.float32
  "torch_dtype": "auto"
  "device_map": "auto"
  # "force_download": True
"rag_model_args": # Put any model arguments required to load your rag model below
  "encoder_model_path": "facebook/bart-large"
  "retriever_model_path": "./checkpoints/rag_retriever"
  "document_dir": "./data/documents"
"quantized_model_args": null # Put any model arguments required to load your quantized model below
